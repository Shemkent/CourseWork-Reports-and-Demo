{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(z):\n",
    "    exp = np.exp(-z)\n",
    "    return 1/(1+exp)\n",
    "\n",
    "#given an obs and weights\n",
    "#returns the probability of P(y=1)\n",
    "# with n = number of features\n",
    "#   weight matrix is nx1 shape\n",
    "#   and that X is r x n\n",
    "def hypothesis(X, W,bias):\n",
    "    # cast to np.array to ensure functions, get T\n",
    "    X = np.matrix(X).T\n",
    "    W = np.matrix(W).T\n",
    "\n",
    "    # eval Z matrix from weights\n",
    "    Z = np.dot(W,X) + bias #output shape 1 x obs\n",
    "    Z = Z.tolist()[0] #cast to simple list\n",
    "\n",
    "    Z = [sigmoid_f(z) for z in Z]\n",
    "    return Z\n",
    "\n",
    "#prediction\n",
    "def classifier_f(X, W,bias):\n",
    "    Z = hypothesis(X, W, bias)\n",
    "\n",
    "    #0.5 breakpoint\n",
    "    def logit_threshold(z):\n",
    "        if(z >= 0.5):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    Z = [logit_threshold(z) for z in Z]\n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume Y is a flat (1xn) list, 2 class\n",
    "# returns Cross Entropy val\n",
    "def binary_loss_f(hypo, y):\n",
    "    hypo = np.matrix(hypo)  # hypothesis\n",
    "    y = np.matrix(y).T\n",
    "\n",
    "    val = np.sum(np.dot(np.log(hypo), y) +\n",
    "                 np.dot(np.log(1-hypo), 1-y))\n",
    "\n",
    "    return (-1/len(y))*val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient calculator\n",
    "def gradient_f(X,W,b,y):\n",
    "    # n*1 shape\n",
    "    error = hypothesis(X, W, b)-y\n",
    "\n",
    "    grad_W = X.T.dot(error) / len(y)\n",
    "    grad_W = np.reshape(grad_W, (-1, 1))\n",
    "    grad_intercept = np.sum(error)/len(y)\n",
    "\n",
    "    return grad_W, grad_intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT DESCENT\n",
    "def optimizer_f(max_iter, alpha,X,y):\n",
    "    #init\n",
    "    W = np.zeros((X.shape[1], 1))\n",
    "    max_iter = max_iter\n",
    "    alpha = alpha\n",
    "    b = 0\n",
    "    cost = None\n",
    "\n",
    "    #select best mechanism\n",
    "    best_W = W.copy()\n",
    "    best_b = 0\n",
    "    best_cost = binary_loss_f(hypothesis(\n",
    "        X, W, b), y)\n",
    "    hist_cost = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grads = gradient_f(X,W,b,y)\n",
    "        grad_W = grads[0]\n",
    "        grad_intercept = grads[1]\n",
    "\n",
    "        #updating \n",
    "        W = W - alpha*grad_W\n",
    "        b = b - alpha*grad_intercept\n",
    "\n",
    "        #select best mechanism\n",
    "        this_cost = binary_loss_f(hypothesis(\n",
    "            X, W, b), y)\n",
    "\n",
    "        #store best params\n",
    "        hist_cost.append(this_cost)\n",
    "        if(this_cost < best_cost):\n",
    "            best_cost = this_cost\n",
    "            best_W = W.copy()\n",
    "            best_b = b\n",
    "\n",
    "    W = best_W\n",
    "    cost = best_cost\n",
    "\n",
    "    return report(W,b,y, hist_cost,cost)\n",
    "\n",
    "def report(W,b,y, hist_cost,cost):\n",
    "    #report coef\n",
    "    print(\"Weights:\")\n",
    "    print(W.T)\n",
    "    print(\"y intercept:\")\n",
    "    print(b)\n",
    "\n",
    "    print(\"cost:\")\n",
    "    print(cost)\n",
    "    error = classifier_f(X, W, b)-Y\n",
    "    print(\"accuracy:\")\n",
    "    print(1-(sum(error)/len(error)))\n",
    "\n",
    "    # show plot\n",
    "    plt.plot(hist_cost)\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "\n",
    "    return W,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#get data\n",
    "data = load_breast_cancer()\n",
    "Y = data.target # this is 0-1 binary, cannot normalize further\n",
    "X = data.data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X) # normalize X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[-1.1434992  -1.30912899 -1.24649986 -1.57207726  0.4750165  -0.71928016\n",
      "  -2.48155437 -3.34113606  0.41115119  2.03552652 -1.64607791  0.46426397\n",
      "  -1.29014345 -1.22181241  0.5989249   0.91627859  0.51280409  0.27778245\n",
      "   0.7602846   0.93372269 -2.3582086  -2.14580201 -2.21834932 -2.15158438\n",
      "  -0.98440036 -1.12134051 -1.78357458 -3.27399809 -1.05564681 -0.1960431 ]]\n",
      "y intercept:\n",
      "7.596854589203278\n",
      "cost:\n",
      "0.12354588987961958\n",
      "accuracy:\n",
      "0.9824253075571178\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = optimizer_f(10000,0.05,X,Y) #10k iter, 0.05 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting results\n",
    "weights = output[0].tolist()\n",
    "\n",
    "dict = {}\n",
    "for i in range(len(weights)):\n",
    "    dict[data.feature_names[i]] = weights[i]\n",
    "\n",
    "output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#'0 = malignant' and '1 = benign'.\n",
    "Ranked Weights:\n",
    "\n",
    "'mean fractal dimension': [2.0355265220523395],\n",
    "'fractal dimension error': [0.9337226886084741],\n",
    "'compactness error': [0.9162785853132651],\n",
    "'symmetry error': [0.7602846015281611],\n",
    "'smoothness error': [0.5989248972791296],\n",
    "'concavity error': [0.5128040934311626],\n",
    "'mean smoothness': [0.4750165032045297],\n",
    "'texture error': [0.4642639706439808],\n",
    "'mean symmetry': [0.41115119203402106],\n",
    "'concave points error': [0.2777824500100443],\n",
    "'worst fractal dimension': [-0.19604310332841782]\n",
    "'mean compactness': [-0.7192801606347963],\n",
    "'worst smoothness': [-0.9844003629135498],\n",
    "'worst symmetry': [-1.055646806870359],\n",
    "'worst compactness': [-1.1213405129065281],\n",
    "'area error': [-1.2218124071745537],\n",
    "'mean perimeter': [-1.2464998617198304],\n",
    "'perimeter error': [-1.2901434487276633],\n",
    "'mean texture': [-1.3091289907027561],\n",
    "'mean radius': [-1.1434992003641462],\n",
    "'mean area': [-1.5720772561423688],\n",
    "'radius error': [-1.6460779103249297],\n",
    "'worst concavity': [-1.783574582148665],\n",
    "'worst texture': [-2.145802008304591],\n",
    "'worst area': [-2.151584376781528],\n",
    "'worst perimeter': [-2.2183493181500524],\n",
    "'worst radius': [-2.358208604270848],\n",
    "'mean concavity': [-2.4815543695584337],\n",
    "'mean concave points': [-3.3411360559613303],\n",
    "'worst concave points': [-3.2739980898775736],\n",
    "\n",
    "All positive (indication for benign) variables are errors of different measurement except mean fractal dimension and mean symmetry. Mean fractal dimension also has the most significant positive coefficient, but we cannot infer much from this as there are many more variables with similarly significant but negative coefficients. \n",
    "\n",
    "The error measurements generally have weak (less than 1.0) coefficients and are consequently less significant to the classification. Mean or worst concavity have the most negative coefficients, followed by many of the “worst” measurements whose coefficients are relatively strong too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "random.seed(265)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainTest_split_CV(X,y,model,train_percent):\n",
    "    #random index\n",
    "    index = list(range(0, len(y)))\n",
    "    random.shuffle(index)\n",
    "\n",
    "    train_index = index[:int(len(y)*train_percent)]\n",
    "    test_index = index[int(len(y)*train_percent):]\n",
    "\n",
    "    #splitting dataset\n",
    "    train_X = np.take(X,train_index,0) #axis = 0, row-wise\n",
    "    train_y = np.take(y,train_index,0) #axis = 0, row-wise\n",
    "    test_X = np.take(X, test_index, 0) #axis = 0, row-wise\n",
    "    test_y = np.take(y, test_index, 0)  # axis = 0, row-wise\n",
    "\n",
    "    #running regression\n",
    "    model.fit(train_X, train_y)\n",
    "    prediction = model.predict(test_X)\n",
    "\n",
    "    return mean_squared_error(test_y, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_CV(X, y, model, k):\n",
    "    #random index\n",
    "    index = list(range(0, len(y)))\n",
    "    random.shuffle(index)\n",
    "\n",
    "    folds_p = np.arange(0.0,1.0, 1.0/k)\n",
    "    folds_p = np.append(folds_p, 1.0)\n",
    "    folds_p = np.delete(folds_p, 0)\n",
    "\n",
    "    folds_costs = []\n",
    "    for i in range(len(folds_p)):\n",
    "        start = int(len(index)*(folds_p[i]-folds_p[0]))\n",
    "        end = int(len(index)*(folds_p[i]))\n",
    "\n",
    "        test_index = index[start:end]\n",
    "        train_index = index[end:]\n",
    "        b = index[:start]\n",
    "        for ind in b: train_index.append(ind)\n",
    "         \n",
    "        #splitting dataset\n",
    "        train_X = np.take(X, train_index, 0)  # axis = 0, row-wise\n",
    "        train_y = np.take(y, train_index, 0)  # axis = 0, row-wise\n",
    "        test_X = np.take(X, test_index, 0)  # axis = 0, row-wise\n",
    "        test_y = np.take(y, test_index, 0)  # axis = 0, row-wise\n",
    "\n",
    "        #running regression\n",
    "        model.fit(train_X, train_y)\n",
    "        prediction = model.predict(test_X)\n",
    "\n",
    "        folds_costs.append(mean_squared_error(test_y, prediction))\n",
    "\n",
    "\n",
    "    return sum(folds_costs)/len(folds_costs)  # avg cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOOCV(X, y, model):\n",
    "    #random index\n",
    "    k = len(y)\n",
    "    index = list(range(0, len(y)))\n",
    "    random.shuffle(index)\n",
    "\n",
    "    folds_costs = []\n",
    "    for i in range(len(index)):\n",
    "        this_index = index.copy()\n",
    "\n",
    "        test_index = this_index.pop(i)\n",
    "        train_index = this_index\n",
    "\n",
    "        #splitting dataset\n",
    "        train_X = np.take(X, train_index, 0)  # axis = 0, row-wise\n",
    "        train_y = np.take(y, train_index, 0)  # axis = 0, row-wise\n",
    "        test_X = np.take(X, test_index, 0)  # axis = 0, row-wise\n",
    "        test_y = np.take(y, test_index, 0)  # axis = 0, row-wise\n",
    "\n",
    "        #running regression\n",
    "        model.fit(train_X, train_y)\n",
    "        prediction = model.predict([test_X, test_X])[0]\n",
    "\n",
    "        folds_costs.append(mean_squared_error(test_y, prediction))\n",
    "\n",
    "    return sum(folds_costs)/len(folds_costs)  # avg cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "#load and separate data\n",
    "calif = fetch_california_housing(as_frame=True)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(calif.frame)  # normalizing\n",
    "\n",
    "X = data[:, 0:8]\n",
    "Y = data[:, [8]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_test split 70% MSE:  0.0225709576136961\n",
      "5Fold MSE:  0.02242545356188667\n",
      "LOOCV MSE:  0.022456875235560322\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "print(\"Train_test split 70% MSE: \", TrainTest_split_CV(X,Y,model,0.7))\n",
    "print(\"5Fold MSE: \", KFold_CV(X, Y, model, 5))\n",
    "print(\"LOOCV MSE: \", LOOCV(X, Y, model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three techniques produces results with very similar, very low error: a very good performance. The low error suggests the model (linear regression) is not overfitting and has a similar level of complexity to the real world. \n",
    "\n",
    "Typically, we expect the model to perform worse when it has less training data. The difference of error in our case is very marginal. This shows that the model used here is adequate since the information lost from using only 70% of the data for training is very close to that of LOOCV which uses all but one observation for training. \n",
    "\n",
    "Granted, comparing performance in such a way is possible as the data set is simple (only 8 variables) and has a relatively large number of observations (20640 observations).\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5336f7fdd4288d794d8a223867d5c29f87bd1c8df6e341cc3223c0dba3028cf2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
